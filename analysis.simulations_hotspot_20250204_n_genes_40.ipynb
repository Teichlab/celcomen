{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import anndata\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# set figure parameters\n",
    "sc.settings.set_figure_params(dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-scheme",
   "metadata": {},
   "source": [
    "## define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to gather positions\n",
    "def get_pos(n_x, n_y):\n",
    "    # create the hex lattice\n",
    "    xs = np.array([np.arange(0, n_x) + 0.5 if idx % 2 == 0 else np.arange(0, n_x) for idx in range(n_y)])\n",
    "    # derive the y-step given a distance of one\n",
    "    y_step = np.sqrt(1**2+0.5**2)\n",
    "    ys = np.array([[y_step * idy] * n_x for idy in range(n_y)])\n",
    "    # define the positions\n",
    "    pos = np.vstack([xs.flatten(), ys.flatten()]).T\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = get_pos(10, 10)\n",
    "plt.scatter( pos[:,0], pos[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to derive the gex from the sphex\n",
    "def calc_gex(sphex):\n",
    "    \"\"\"\n",
    "    Calculates the gene expression matrix from the spherical\n",
    "    \"\"\"\n",
    "    # setup the gex\n",
    "    n_genes = sphex.shape[1]+1\n",
    "    gex = torch.from_numpy(np.ones((sphex.shape[0], n_genes)).astype('float32')).to(device)\n",
    "    # compute the gex\n",
    "    for idx in range(n_genes):\n",
    "        for idx_ in range(idx):\n",
    "            gex[:,idx] *= torch.sin(sphex[:,idx_])\n",
    "        if idx < n_genes-1:\n",
    "            gex[:,idx] *= torch.cos(sphex[:,idx])\n",
    "    return torch.nan_to_num(gex).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "# define the number of neighbors (six for visium)\n",
    "n_neighbors = 6\n",
    "# define the simcomen class\n",
    "class simcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(simcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.sphex = None\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(n_genes).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_sphex(self, sphex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.sphex = torch.nn.Parameter(sphex, requires_grad=True)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the gex\n",
    "        self.gex = calc_gex(self.sphex)\n",
    "        edge_index = edge_index.to(device)\n",
    "        \n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the celcomen class\n",
    "class celcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(celcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=True)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=True)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_gex(self, gex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.gex = torch.nn.Parameter(gex, requires_grad=False)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to normalize the g2g\n",
    "def normalize_g2g(g2g):\n",
    "    \"\"\"\n",
    "    Addresses any small fluctuations in symmetrical weights\n",
    "    \"\"\"\n",
    "    # symmetrize the values\n",
    "    g2g = (g2g + g2g.T) / 2\n",
    "    # force them to be between 0-1\n",
    "    g2g[g2g < 0] = 0\n",
    "    g2g[g2g > 1] = 1\n",
    "    # force the central line to be 1\n",
    "    for idx in range(len(g2g)):\n",
    "        g2g[idx, idx] = 1\n",
    "    return g2g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-miniature",
   "metadata": {},
   "source": [
    "## perform simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original: NO jump start\n",
    "\n",
    "\n",
    "def run_scc(input_g2g, params, plot=False):\n",
    "    # define the hyperparameters\n",
    "    n_x, n_y, n_genes = params[:3]\n",
    "    learning_rate = params[3]\n",
    "    zmft_scalar = params[4]\n",
    "    seed = params[5]\n",
    "    epochs = params[6]\n",
    "    # instantiate the model, input and output will be the same\n",
    "    model = simcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "    \n",
    "    # now perform the simulation\n",
    "    np.random.seed(seed)\n",
    "    # retrieve the positions\n",
    "    pos = torch.from_numpy(get_pos(n_x, n_y).astype('float32'))\n",
    "    # find the edges via kneighbors, not including self because we are considering intercellular\n",
    "    edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "    edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "    # artifically set the g2g matrix\n",
    "    model.set_g2g(input_g2g)\n",
    "    model.set_g2g_intra(input_g2g)\n",
    "\n",
    "    # initialize a gene expression matrix\n",
    "    input_sphex = np.random.normal(np.pi/4, np.pi/8, size=(pos.shape[0], n_genes-1)).astype('float32')\n",
    "    model.set_sphex(torch.from_numpy(input_sphex.copy()))\n",
    "\n",
    "    # move to device\n",
    "    model.to(device)\n",
    "    # train the model\n",
    "    model.train()\n",
    "            \n",
    "    # set up the optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "    # keep track of the losses per data object\n",
    "    loss, losses = None, []\n",
    "\n",
    "    # work through epochs\n",
    "    for epoch in range(epochs):\n",
    "        # derive the message as well as the mean field approximation\n",
    "        msg, msg_intra, log_z_mft = model(edge_index, 1)\n",
    "        if epoch == 0:\n",
    "            input_gex, input_msg = model.gex.clone().detach().cpu().numpy(), msg.clone().detach().cpu().numpy()\n",
    "        # compute the loss and track it\n",
    "        loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model.gex))) )\n",
    "        losses.append(loss.detach().cpu().numpy()[0][0])\n",
    "        # derive the gradients, update, and clear\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # create the plot\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=[6, 4])\n",
    "        ax.grid(False)\n",
    "        ax.plot(losses, lw=2, color='#fe86a4')\n",
    "        ax.set_xlim(0, epochs)\n",
    "        vmin, vmax = min(min(losses), 0), max(losses)\n",
    "        vstep = (vmax - vmin) * 0.01\n",
    "        ax.set_ylim(vmin-vstep, vmax+vstep)\n",
    "        ax.set(xlabel='epochs', ylabel='loss')\n",
    "\n",
    "    spearman_corr, pval = ss.spearmanr( losses, sorted(losses) )\n",
    "    # print(f\"spearman_corr={spearman_corr}\")\n",
    "\n",
    "    # retrieve the data\n",
    "    output_gex = model.gex.detach().cpu().numpy()\n",
    "    output_msg = msg.detach().cpu().numpy()\n",
    "    exp_g2g = input_g2g.detach().cpu().numpy()\n",
    "    # plot the correlations\n",
    "    if plot:\n",
    "        for matrix in [input_gex, input_msg, output_gex, output_msg]:\n",
    "            g = sns.clustermap(pd.DataFrame(matrix).corr(method='spearman'), cmap='seismic', row_cluster=False, col_cluster=False, vmin=-1, vmax=1,\n",
    "                               figsize=[1+n_genes*0.5, 1+n_genes*0.5], dendrogram_ratio=0.1, cbar_pos=(-0.1, 1, .02, .12))\n",
    "            g.ax_heatmap.grid(False)\n",
    "            g.ax_cbar.grid(False)\n",
    "            g.ax_heatmap.tick_params(labelrotation=0)\n",
    "        # plot the expected g2g matrix\n",
    "        g = sns.clustermap(exp_g2g, cmap='seismic', row_cluster=False, col_cluster=False, vmin=-1, vmax=1,\n",
    "                           figsize=[1+n_genes*0.5, 1+n_genes*0.5], dendrogram_ratio=0.1, cbar_pos=(-0.1, 1, .02, .12))\n",
    "        g.ax_heatmap.grid(False)\n",
    "        g.ax_cbar.grid(False)\n",
    "        g.ax_heatmap.tick_params(labelrotation=0)\n",
    "        \n",
    "    return losses, input_gex, output_gex, exp_g2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ccc_from_scc(output_gex, params, plot=False):\n",
    "    # define the hyperparameters\n",
    "    n_x, n_y, n_genes = params[:3]\n",
    "    learning_rate = params[3]\n",
    "    zmft_scalar = params[4]\n",
    "    seed = params[5]\n",
    "    epochs = params[6]\n",
    "    \n",
    "    # retrieve the positions\n",
    "    pos = torch.from_numpy(get_pos(n_x, n_y).astype('float32'))\n",
    "    # find the edges via kneighbors, not including self because we are considering intercellular\n",
    "    edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "    edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "    edge_index = edge_index.to(device)\n",
    "    \n",
    "    # instantiate the model, input and output will be the same\n",
    "    model_rev = celcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "    \n",
    "    # now perform the simulation\n",
    "    np.random.seed(seed)\n",
    "    # artifically set the g2g matrix\n",
    "    input_g2g = np.random.uniform(size=(n_genes, n_genes)).astype('float32')\n",
    "    input_g2g = normalize_g2g((input_g2g + input_g2g.T) / 2)\n",
    "    model_rev.set_g2g(torch.from_numpy(input_g2g))\n",
    "    model_rev.set_g2g_intra(torch.from_numpy(input_g2g))\n",
    "    # initialize a gene expression matrix\n",
    "    model_rev.set_gex(torch.from_numpy(output_gex))\n",
    "    \n",
    "    # setup the initial optimizer\n",
    "    optimizer = torch.optim.SGD(model_rev.parameters(), lr=learning_rate, momentum=0)\n",
    "    # keep track of the losses per data object\n",
    "    loss, losses = None, []\n",
    "    # train the model\n",
    "    model_rev.train()\n",
    "    model_rev.to(device)\n",
    "    \n",
    "    # work through epochs\n",
    "    for epoch in range(epochs):\n",
    "        # derive the message as well as the mean field approximation\n",
    "        msg, msg_intra, log_z_mft = model_rev(edge_index, 1)\n",
    "        # compute the loss and track it\n",
    "        loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model_rev.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model_rev.gex))) )\n",
    "        losses.append(loss.detach().cpu().numpy()[0][0])\n",
    "        # derive the gradients, update, and clear\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # repeatedly force a normalization\n",
    "        model_rev.conv1.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev.conv1.lin.weight), requires_grad=True)\n",
    "        model_rev.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev.lin.weight), requires_grad=True)\n",
    "        optimizer = torch.optim.SGD(model_rev.parameters(), lr=learning_rate, momentum=0)\n",
    "        \n",
    "    # create the plot\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=[6, 4])\n",
    "        ax.grid(False)\n",
    "        ax.plot(losses, lw=2, color='#fe86a4')\n",
    "        ax.set_xlim(0, epochs)\n",
    "        vmin, vmax = min(min(losses), 0), max(losses)\n",
    "        vstep = (vmax - vmin) * 0.01\n",
    "        ax.set_ylim(vmin-vstep, vmax+vstep)\n",
    "        ax.set(xlabel='epochs', ylabel='loss')\n",
    "    \n",
    "    # retrieve the data\n",
    "    obs_g2g_ccc = model_rev.conv1.lin.weight.clone().detach().cpu().numpy()\n",
    "    if plot:\n",
    "        g = sns.clustermap(obs_g2g_ccc, cmap='seismic', row_cluster=False, col_cluster=False, vmin=-1, vmax=1,\n",
    "                           figsize=[1+n_genes*0.5, 1+n_genes*0.5], dendrogram_ratio=0.1, cbar_pos=(-0.1, 1, .02, .12))\n",
    "        g.ax_heatmap.grid(False)\n",
    "        g.ax_cbar.grid(False)\n",
    "        g.ax_heatmap.tick_params(labelrotation=0)\n",
    "    obs_g2g_intra = model_rev.lin.weight.clone().detach().cpu().numpy()\n",
    "    if plot:\n",
    "        g = sns.clustermap(obs_g2g_intra, cmap='seismic', row_cluster=False, col_cluster=False, vmin=-1, vmax=1,\n",
    "                           figsize=[1+n_genes*0.5, 1+n_genes*0.5], dendrogram_ratio=0.1, cbar_pos=(-0.1, 1, .02, .12))\n",
    "        g.ax_heatmap.grid(False)\n",
    "        g.ax_cbar.grid(False)\n",
    "        g.ax_heatmap.tick_params(labelrotation=0)\n",
    "\n",
    "    return losses, obs_g2g_ccc, obs_g2g_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate a random g2g interaction matrix\n",
    "def gen_g2g(n_genes):\n",
    "    # sample the interaction terms and guarantee at least one interaction\n",
    "    p = ss.uniform.rvs(size=1)[0]\n",
    "    intrxns = [0]\n",
    "    # we continously sample until we get interactions that do are not all empty or full\n",
    "    while (np.mean(intrxns) == 0.0) | (np.mean(intrxns) == 1.0):\n",
    "        intrxns = ss.binom.rvs(1, p, size=sum(list(range(n_genes))))\n",
    "    # fill in the input g2g with the appropriate terms\n",
    "    input_g2g = np.ones((n_genes, n_genes)).astype('float32')\n",
    "    idz = 0\n",
    "    for idx in range(n_genes-1):\n",
    "        for idy in range(idx+1, n_genes):\n",
    "            input_g2g[idx, idy] = intrxns[idz]\n",
    "            input_g2g[idy, idx] = intrxns[idz]\n",
    "            idz += 1\n",
    "    input_g2g = torch.tensor(input_g2g)\n",
    "    return input_g2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_g2g_uni(n_genes):\n",
    "    # sample the interaction terms and guarantee at least one interaction\n",
    "    # intrxns = ss.randint.rvs(size=sum(list(range(n_genes))))\n",
    "    intrxns = np.random.randint(0, sum(list(range(n_genes))),size=sum(list(range(n_genes)))   )/sum(list(range(n_genes)))\n",
    "    # fill in the input g2g with the appropriate terms\n",
    "    input_g2g = np.ones((n_genes, n_genes)).astype('float32')\n",
    "    idz = 0\n",
    "    for idx in range(n_genes-1):\n",
    "        for idy in range(idx+1, n_genes):\n",
    "            input_g2g[idx, idy] = intrxns[idz]\n",
    "            input_g2g[idy, idx] = intrxns[idz]\n",
    "            idz += 1\n",
    "    input_g2g = torch.tensor(input_g2g)\n",
    "    return input_g2g\n",
    "\n",
    "# gen_g2g_uni(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81d810-d6a1-4244-8170-d4ed08c0abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim_vs_hotspot(params):\n",
    "    # unpack the parameters\n",
    "    n_x, n_y, n_genes, learning_rate, zmft_scalar, seed, epochs = params\n",
    "    # set the seed\n",
    "    np.random.seed(seed)\n",
    "    # define the input g2g\n",
    "    #input_g2g = gen_g2g(n_genes)\n",
    "    input_g2g = gen_g2g_uni(n_genes)\n",
    "    # run the simulation\n",
    "    losses_scc, input_gex, output_gex, exp_g2g = run_scc(input_g2g, params)\n",
    "\n",
    "    # remove negatives in output_gex\n",
    "    # output_gex -= output_gex.min() \n",
    "    output_gex[ output_gex<0 ] = 0\n",
    "    \n",
    "    # create anndata for hotspot\n",
    "    adata = anndata.AnnData(X=output_gex)\n",
    "    adata.layers[\"counts\"] = adata.X\n",
    "    adata.obsm[\"spatial\"] = np.array(pos)\n",
    "    adata.obs[\"total_counts\"] = np.sum( adata.X, axis=1 )\n",
    "\n",
    "    # create hotspot object\n",
    "    hs = hotspot.Hotspot(\n",
    "        adata,\n",
    "        layer_key=\"counts\",\n",
    "        model='danb',\n",
    "        latent_obsm_key=\"spatial\",\n",
    "        umi_counts_obs_key=\"total_counts\"\n",
    "    )\n",
    "\n",
    "    # run hotspot\n",
    "    hs.create_knn_graph(weighted_graph=False, n_neighbors=6)\n",
    "    hs_results = hs.compute_autocorrelations()\n",
    "    hs_genes = hs_results.index # Select all genes\n",
    "    local_correlations = hs.compute_local_correlations(hs_genes) \n",
    "        \n",
    "\n",
    "    # define results from ccc\n",
    "    losses_ccc, obs_g2g_ccc, obs_g2g_intra = run_ccc_from_scc(output_gex, params)\n",
    "    # print(f\"output_gex={np.round(output_gex, 2)}\")\n",
    "    obs_g2g = obs_g2g_ccc.copy()\n",
    "    # instantiate a series of the results\n",
    "    results = pd.Series()\n",
    "    results.loc['loss_sce'] = losses_scc[-1]\n",
    "    results.loc['loss_cce'] = losses_ccc[-1]\n",
    "    \n",
    "    # derive the correlation (from ccc)\n",
    "    rho, pval = ss.spearmanr(obs_g2g.flatten(), exp_g2g.flatten())\n",
    "    rhos_list.append(rho)\n",
    "    results.loc['spearman_cce_out_vs_sce_in.r'] = rho\n",
    "    results.loc['spearman_cce_out_vs_sce_in.p'] = pval\n",
    "    \n",
    "    # derive the correlation (correlations of the gex)\n",
    "    gex_corr = pd.DataFrame(output_gex).corr(method='spearman').values\n",
    "    rho, pval = ss.spearmanr(gex_corr.flatten(), exp_g2g.flatten())   \n",
    "    results.loc['spearman_sce_gex_corr_vs_sce_in.r'] = rho\n",
    "    results.loc['spearman_sce_gex_corr_vs_sce_in.p'] = pval\n",
    "    \n",
    "    # derive the correlation (correlations of the gex)\n",
    "    gex_corr = pd.DataFrame(input_gex).corr(method='spearman').values\n",
    "    rho, pval = ss.spearmanr(gex_corr.flatten(), exp_g2g.flatten())      \n",
    "    results.loc['spearman_in_gex_corr_vs_sce_in.r'] = rho\n",
    "    results.loc['spearman_in_gex_corr_vs_sce_in.p'] = pval\n",
    "\n",
    "    # derive the correlation (from hotspot)\n",
    "    rho, pval = ss.spearmanr(local_correlations.to_numpy().flatten(), exp_g2g.flatten())\n",
    "\n",
    "    results.loc['spearman_hotspot.r'] = rho\n",
    "    results.loc['spearman_hotspot.p'] = pval\n",
    "    \n",
    "    # name it based on the seed\n",
    "    results.name = f'seed_{seed}'\n",
    "    results_ccc = results.copy()\n",
    "\n",
    "    results_intra = results.copy()\n",
    "    \n",
    "    return results_ccc, results_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4b62c-6c40-49b5-ac9e-179c3e42f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import hotspot\n",
    "rhos_list = []\n",
    "# define the parameters\n",
    "n_x, n_y, n_genes = 10, 10, 40\n",
    "learning_rate = 5e-2       # 1e-1\n",
    "zmft_scalar = 0.01\n",
    "epochs = 300\n",
    "# define the parameters\n",
    "n_sims = 50\n",
    "params_list = [[n_x, n_y, n_genes, learning_rate, zmft_scalar, seed, epochs] for seed in list(range(0,100*n_sims, 100) ) ]\n",
    "# run the simulations\n",
    "results_list = []\n",
    "t0 = time.time()\n",
    "for i, params in enumerate(params_list):\n",
    "    results = run_sim_vs_hotspot(params)\n",
    "    results_list.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-cylinder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the order of the metrics\n",
    "order = ['loss_sce','loss_ccc',\n",
    "         'spearman_ccc_out_vs_sce_in.r','spearman_ccc_out_vs_sce_in.p',\n",
    "         'spearman_sce_gex_corr_vs_sce_in.r','spearman_sce_gex_corr_vs_sce_in.p',\n",
    "         # 'spearman_in_gex_corr_vs_scc_in.r','spearman_in_gex_corr_vs_scc_in.p', \n",
    "         'spearman_hotspot.r', 'spearman_hotspot.p']\n",
    "results_ccc = pd.concat([el[0] for el in results_list], axis=1).loc[order]\n",
    "# results_intra = pd.concat([el[1] for el in results_list], axis=1).loc[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b6ba3-d42c-4a84-9df1-8cf45c879069",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd8f6e-5392-4bfb-8a8d-f6f522bfc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt the dataframe into a plottable function (complete this for CCC as before)\n",
    "data = results_ccc.reset_index().melt(id_vars='index')\n",
    "data['dataset'] = data['index'].apply(lambda x: '_'.join(x.split('_')[1:]).split('_vs_')[0]).str.replace('_','-')\n",
    "data['metric'] = data['index'].apply(lambda x: x.split('_')[0]+'.'+x.split('.')[-1])\n",
    "data['nlog10p1en4_value'] = -np.log10(data['value'].astype(float)+1e-4)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d248d87-9046-4e8b-aec9-53edcfcb3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the things we wish to plot\n",
    "plotters = [\n",
    "            ['spearman.r', 'value', [ 'hotspot.r', 'sce-gex-corr', 'cce-out', ]],\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-right",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# run through all of the plots\n",
    "for metric, value, datasets in plotters:\n",
    "    # plot key pairwise metrics\n",
    "    fig, ax = plt.subplots(figsize=[3, 4])\n",
    "    ax.grid(False)\n",
    "    ax = sns.boxplot(x='dataset', y=value, data=data.loc[data['metric'] == metric], zorder=0,\n",
    "                     saturation=1, ax=ax, order=datasets, linecolor='k', linewidth=2, palette=['#cc78bc','#fbafe4', '#92c5de'])\n",
    "    ax = sns.stripplot(x='dataset', y=value, data=data.loc[data['metric'] == metric], zorder=2,\n",
    "                       ax=ax, order=datasets, edgecolor='k', linewidth=1, jitter=0.25, alpha=0.5, palette=['#cc78bc','#fbafe4','#92c5de'])\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    if value == 'nlog10p1en4_value':\n",
    "        ax.set_ylabel(f'-log10({metric}+1e-4)')\n",
    "    else:\n",
    "        ax.set_ylabel(f'{metric}')\n",
    "    # derive the values\n",
    "    x1 = data.loc[(data['metric'] == metric)&(data['dataset'] == datasets[0]), value].reset_index().iloc[:, 1]\n",
    "    x2 = data.loc[(data['metric'] == metric)&(data['dataset'] == datasets[1]), value].reset_index().iloc[:, 1]\n",
    "    mask = (~x1.isna()) & (~x2.isna())\n",
    "    x1, x2 = x1.loc[mask], x2.loc[mask]\n",
    "    # derive the p-value\n",
    "    pval1 = ss.wilcoxon(x1, x2)[1]\n",
    "    pval2 = ss.ttest_rel(x1, x2)[1]\n",
    "\n",
    "    # derive the values\n",
    "    x1 = data.loc[(data['metric'] == metric)&(data['dataset'] == datasets[0]), value].reset_index().iloc[:, 1]\n",
    "    x2 = data.loc[(data['metric'] == metric)&(data['dataset'] == datasets[2]), value].reset_index().iloc[:, 1]\n",
    "    mask = (~x1.isna()) & (~x2.isna())\n",
    "    x1, x2 = x1.loc[mask], x2.loc[mask]\n",
    "    # derive the p-value\n",
    "    pval3 = ss.wilcoxon(x1, x2)[1]\n",
    "    pval4 = ss.ttest_rel(x1, x2)[1]\n",
    "    \n",
    "    text = ' SCE wilcoxon paired p = %.3e' % pval1\n",
    "    text += '\\n SCE t-test paired p = %.3e' % pval2\n",
    "    text += '\\n CCE wilcoxon paired p = %.3e' % pval3\n",
    "    text += '\\n CCE t-test paired p = %.3e' % pval4\n",
    "    ax.text(1.03, .99, text, va='top', ha='left', transform=ax.transAxes)\n",
    "    ax.set_xlim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3380aac-dfb9-4eff-8aa2-45936ad64159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celcomen_tutorial_env",
   "language": "python",
   "name": "celcomen_tutorial_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
