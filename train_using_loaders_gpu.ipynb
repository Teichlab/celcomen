{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anonymous-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celcomen.models.celcomen import celcomen\n",
    "from celcomen.models.simcomen import simcomen\n",
    "from celcomen.utils.helpers import normalize_g2g, calc_sphex, calc_gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aboriginal-discharge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/team205/sm58/packages/celcomen_trials/celcomen_final\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "billion-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facial-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "national-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "def get_dataset_loaders(h5ad_path: str, sample_id_name: str, n_neighbors: int, verbose: bool):\n",
    "\n",
    "    adata = sc.read_h5ad(h5ad_path) \n",
    "\n",
    "    adata_list = [  adata[adata.obs[sample_id_name]==i] for i in set(adata.obs[sample_id_name])  ]\n",
    "\n",
    "    data_list = []\n",
    "    n_neighbors = 6\n",
    "\n",
    "    for adata in adata_list:\n",
    "        pos = torch.from_numpy(adata.obsm[\"spatial\"])\n",
    "        x = torch.from_numpy(adata.X.todense())    # here x is nodes x 33500 -> add filteration here to take \"best\" 100\n",
    "        # normalize x \n",
    "        norm_factor = torch.pow(x,2).sum(1).reshape(-1,1)\n",
    "        x = torch.div(x, norm_factor)\n",
    "        y = torch.Tensor([0])   # here we will store GT value\n",
    "        #edge_index = knn_graph(pos, k=n_neighbors)\n",
    "        edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "        edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "        data = torch_geometric.data.Data(x=x, pos=pos, y=y, edge_index=edge_index)\n",
    "        data.validate(raise_on_error=True)    # performs basic checks on the graph\n",
    "        data_list.append(data)\n",
    "\n",
    "    loader = DataLoader( data_list, batch_size=1, shuffle=True)\n",
    "\n",
    "    if verbose:\n",
    "        for step, data in enumerate(loader):\n",
    "            print(f'Step {step+1}')\n",
    "            print(\"=====\")\n",
    "            print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "            print(data)\n",
    "            print()\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinguished-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[4243, 33538], edge_index=[2, 25458], y=[1], pos=[4243, 2], batch=[4243], ptr=[2])\n",
      "\n",
      "Step 2\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3400, 33538], edge_index=[2, 20400], y=[1], pos=[3400, 2], batch=[3400], ptr=[2])\n",
      "\n",
      "Step 3\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3430, 33538], edge_index=[2, 20580], y=[1], pos=[3430, 2], batch=[3430], ptr=[2])\n",
      "\n",
      "Step 4\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3802, 33538], edge_index=[2, 22812], y=[1], pos=[3802, 2], batch=[3802], ptr=[2])\n",
      "\n",
      "Step 5\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[2881, 33538], edge_index=[2, 17286], y=[1], pos=[2881, 2], batch=[2881], ptr=[2])\n",
      "\n",
      "Step 6\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3448, 33538], edge_index=[2, 20688], y=[1], pos=[3448, 2], batch=[3448], ptr=[2])\n",
      "\n",
      "Step 7\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3052, 33538], edge_index=[2, 18312], y=[1], pos=[3052, 2], batch=[3052], ptr=[2])\n",
      "\n",
      "Step 8\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[2852, 33538], edge_index=[2, 17112], y=[1], pos=[2852, 2], batch=[2852], ptr=[2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h5ad_path=\"data/visium-OCT_SAN_raw.h5ad\"\n",
    "\n",
    "loader = get_dataset_loaders(\"data/visium-OCT_SAN_raw.h5ad\", \"sangerID\", 6, True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "anticipated-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "            \n",
    "            \n",
    "def train(num_epochs, learning_rate, model, loader, zmft_scalar=1e-1, seed=1, device=\"cpu\"):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "    losses = []\n",
    "    model.train()\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        losses_= []\n",
    "\n",
    "        for data in loader:\n",
    "            # move data to device\n",
    "            data = data.to(device)\n",
    "            # train loader  # Iterate in batches over the training dataset.\n",
    "            # set the appropriate gex\n",
    "            model.set_gex(data.x)\n",
    "            # derive the message as well as the mean field approximation\n",
    "            msg, msg_intra, log_z_mft = model(data.edge_index, 1)\n",
    "            # compute the loss and track it\n",
    "            loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model.gex))) )\n",
    "            if device==\"cpu\":\n",
    "                losses_.append(loss.detach().numpy()[0][0])\n",
    "            else:\n",
    "                losses_.append(loss.detach().cpu().numpy()[0][0])\n",
    "            # derive the gradients, update, and clear\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # repeatedly force a normalization\n",
    "            model.conv1.lin.weight = torch.nn.Parameter(normalize_g2g(model.conv1.lin.weight), requires_grad=True)\n",
    "            model.lin.weight = torch.nn.Parameter(normalize_g2g(model.lin.weight), requires_grad=True)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "            \n",
    "        print(f\"Loss={np.mean(losses_)}\")\n",
    "        losses.append(np.mean(losses_))\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c8c222-7776-42bf-b071-6f145ad1bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lovely-chance",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.19 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 77.18 GiB memory in use. Of the allocated memory 75.16 GiB is allocated by PyTorch, and 1.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-1\u001b[39m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m celcomen(input_dim\u001b[38;5;241m=\u001b[39mn_genes, output_dim\u001b[38;5;241m=\u001b[39mn_genes, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m losses \u001b[38;5;241m=\u001b[39m train(epochs, learning_rate, model, loader, zmft_scalar\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-1\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/nfs/team205/sm58/packages/celcomen_trials/pyg_env/celcomen_tutorial_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/team205/sm58/packages/celcomen_trials/pyg_env/celcomen_tutorial_env/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/nfs/team205/sm58/packages/celcomen_trials/pyg_env/celcomen_tutorial_env/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/nfs/team205/sm58/packages/celcomen_trials/pyg_env/celcomen_tutorial_env/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/nfs/team205/sm58/packages/celcomen_trials/pyg_env/celcomen_tutorial_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.19 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 77.18 GiB memory in use. Of the allocated memory 75.16 GiB is allocated by PyTorch, and 1.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "n_genes=33538\n",
    "n_neighbors=6\n",
    "seed=1\n",
    "zmft_scalar = 5e-2\n",
    "epochs = 10\n",
    "learning_rate = 5e-1\n",
    "\n",
    "\n",
    "model = celcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "model.to(\"cuda\")\n",
    "losses = train(epochs, learning_rate, model, loader, zmft_scalar=1e-1, seed=1, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f801ce3-6b93-41c2-9c11-c668a85a69e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'epochs'), Text(0, 0.5, 'loss')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the plot\n",
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax.grid(False)\n",
    "ax.plot(losses, lw=2, color='#fe86a4')\n",
    "ax.set_xlim(0, epochs)\n",
    "vmin, vmax = min(min(losses), 0), max(losses)\n",
    "vstep = (vmax - vmin) * 0.01\n",
    "ax.set_ylim(vmin-vstep, vmax+vstep)\n",
    "ax.set(xlabel='epochs', ylabel='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alien-television",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spot_id\n",
       "HCAHeartST10659160_AAACAACGAATAGTTC-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACAAGTATCTCCCA-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACAATCTACTAGCA-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACACCAATAACTGC-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACAGAGCGACTCCT-1    HCAHeartST10659160\n",
       "                                                ...        \n",
       "HCAHeartST13233999_TTGTTCAGTGTGCTAC-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTCTAGATACGCT-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTGTGTGTCAAGA-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTTCCATACAACT-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTTGTGTAAATTC-1    HCAHeartST13233999\n",
       "Name: sangerID, Length: 27108, dtype: category\n",
       "Categories (8, object): ['HCAHeartST10659160', 'HCAHeartST12992072', 'HCAHeartST13228105', 'HCAHeartST13228106', 'HCAHeartST13233996', 'HCAHeartST13233997', 'HCAHeartST13233998', 'HCAHeartST13233999']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(h5ad_path) \n",
    "adata.obs[\"sangerID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bottom-lesson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 27108 × 33538\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'sample', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'mt_frac', 'n_counts', 'n_genes', 'annotation_JC', 'sangerID', 'Publication', 'combinedID', 'donor', 'donor_type', 'region', 'region_finest', 'age', 'gender', 'facility', 'cell_or_nuclei', 'modality', 'kit_10x', 'flushed', 'region_cell2loc'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'SYMBOL'\n",
       "    uns: 'spatial'\n",
       "    obsm: 'MT', 'means_cell_abundance_w_sf', 'q05_cell_abundance_w_sf', 'q95_cell_abundance_w_sf', 'spatial', 'stds_cell_abundance_w_sf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-period",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celcomen_tutorial_env",
   "language": "python",
   "name": "celcomen_tutorial_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
