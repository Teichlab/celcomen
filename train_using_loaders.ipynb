{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celcomen.models.celcomen import celcomen\n",
    "from celcomen.models.simcomen import simcomen\n",
    "from celcomen.utils.helpers import normalize_g2g, calc_sphex, calc_gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aboriginal-discharge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/team205/sm58/packages/celcomen_trials/celcomen_final\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "billion-survivor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facial-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "national-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "def get_dataset_loaders(h5ad_path: str, sample_id_name: str, n_neighbors: int, verbose: bool):\n",
    "\n",
    "    adata = sc.read_h5ad(h5ad_path) \n",
    "\n",
    "    adata_list = [  adata[adata.obs[sample_id_name]==i] for i in set(adata.obs[sample_id_name])  ]\n",
    "\n",
    "    data_list = []\n",
    "    n_neighbors = 6\n",
    "\n",
    "    for adata in adata_list:\n",
    "        pos = torch.from_numpy(adata.obsm[\"spatial\"])\n",
    "        x = torch.from_numpy(adata.X.todense())    # here x is nodes x 33500 -> add filteration here to take \"best\" 100\n",
    "        # normalize x \n",
    "        norm_factor = torch.pow(x,2).sum(1).reshape(-1,1)\n",
    "        x = torch.div(x, norm_factor)\n",
    "        y = torch.Tensor([0])   # here we will store GT value\n",
    "        #edge_index = knn_graph(pos, k=n_neighbors)\n",
    "        edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "        edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "        data = torch_geometric.data.Data(x=x, pos=pos, y=y, edge_index=edge_index)\n",
    "        data.validate(raise_on_error=True)    # performs basic checks on the graph\n",
    "        data_list.append(data)\n",
    "\n",
    "    loader = DataLoader( data_list, batch_size=1, shuffle=True)\n",
    "\n",
    "    if verbose:\n",
    "        for step, data in enumerate(loader):\n",
    "            print(f'Step {step+1}')\n",
    "            print(\"=====\")\n",
    "            print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "            print(data)\n",
    "            print()\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distinguished-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3448, 33538], edge_index=[2, 20688], y=[1], pos=[3448, 2], batch=[3448], ptr=[2])\n",
      "\n",
      "Step 2\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[2881, 33538], edge_index=[2, 17286], y=[1], pos=[2881, 2], batch=[2881], ptr=[2])\n",
      "\n",
      "Step 3\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3400, 33538], edge_index=[2, 20400], y=[1], pos=[3400, 2], batch=[3400], ptr=[2])\n",
      "\n",
      "Step 4\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3802, 33538], edge_index=[2, 22812], y=[1], pos=[3802, 2], batch=[3802], ptr=[2])\n",
      "\n",
      "Step 5\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[2852, 33538], edge_index=[2, 17112], y=[1], pos=[2852, 2], batch=[2852], ptr=[2])\n",
      "\n",
      "Step 6\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3430, 33538], edge_index=[2, 20580], y=[1], pos=[3430, 2], batch=[3430], ptr=[2])\n",
      "\n",
      "Step 7\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[3052, 33538], edge_index=[2, 18312], y=[1], pos=[3052, 2], batch=[3052], ptr=[2])\n",
      "\n",
      "Step 8\n",
      "=====\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[4243, 33538], edge_index=[2, 25458], y=[1], pos=[4243, 2], batch=[4243], ptr=[2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h5ad_path=\"data/visium-OCT_SAN_raw.h5ad\"\n",
    "\n",
    "loader = get_dataset_loaders(\"data/visium-OCT_SAN_raw.h5ad\", \"sangerID\", 6, True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "anticipated-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "            \n",
    "            \n",
    "def train(num_epochs, learning_rate, model, loader, zmft_scalar=1e-1, seed=1, device=\"cpu\"):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "    losses = []\n",
    "    model.train()\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        losses_= []\n",
    "\n",
    "        for data in loader:\n",
    "            print(\"batch\")\n",
    "            # move data to device\n",
    "            data = data.to(device)\n",
    "            # train loader  # Iterate in batches over the training dataset.\n",
    "            # set the appropriate gex\n",
    "            model.set_gex(data.x)\n",
    "            # derive the message as well as the mean field approximation\n",
    "            msg, msg_intra, log_z_mft = model(data.edge_index, 1)\n",
    "            # compute the loss and track it\n",
    "            loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model.gex))) )\n",
    "            print(\"loss\")\n",
    "            losses_.append(loss.detach().numpy()[0][0])\n",
    "            print(\"append\")\n",
    "            # derive the gradients, update, and clear\n",
    "            loss.backward()\n",
    "            print(\"back\")\n",
    "            optimizer.step()\n",
    "            print(\"step\")\n",
    "            optimizer.zero_grad()\n",
    "            # repeatedly force a normalization\n",
    "            model.conv1.lin.weight = torch.nn.Parameter(normalize_g2g(model.conv1.lin.weight), requires_grad=True)\n",
    "            model.lin.weight = torch.nn.Parameter(normalize_g2g(model.lin.weight), requires_grad=True)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "            \n",
    "        print(f\"Loss={np.mean(losses_)}\")\n",
    "        losses.append(np.mean(losses_))\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "Loss=2354.8935546875\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n",
      "loss\n",
      "append\n",
      "back\n",
      "step\n",
      "batch\n"
     ]
    }
   ],
   "source": [
    "n_genes=33538\n",
    "n_neighbors=6\n",
    "seed=1\n",
    "zmft_scalar = 1e-1\n",
    "epochs = 10\n",
    "learning_rate = 5e-2\n",
    "\n",
    "\n",
    "model = celcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "\n",
    "train(epochs, learning_rate, model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f801ce3-6b93-41c2-9c11-c668a85a69e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alien-television",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spot_id\n",
       "HCAHeartST10659160_AAACAACGAATAGTTC-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACAAGTATCTCCCA-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACAATCTACTAGCA-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACACCAATAACTGC-1    HCAHeartST10659160\n",
       "HCAHeartST10659160_AAACAGAGCGACTCCT-1    HCAHeartST10659160\n",
       "                                                ...        \n",
       "HCAHeartST13233999_TTGTTCAGTGTGCTAC-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTCTAGATACGCT-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTGTGTGTCAAGA-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTTCCATACAACT-1    HCAHeartST13233999\n",
       "HCAHeartST13233999_TTGTTTGTGTAAATTC-1    HCAHeartST13233999\n",
       "Name: sangerID, Length: 27108, dtype: category\n",
       "Categories (8, object): ['HCAHeartST10659160', 'HCAHeartST12992072', 'HCAHeartST13228105', 'HCAHeartST13228106', 'HCAHeartST13233996', 'HCAHeartST13233997', 'HCAHeartST13233998', 'HCAHeartST13233999']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(h5ad_path) \n",
    "adata.obs[\"sangerID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bottom-lesson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 27108 × 33538\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'sample', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'mt_frac', 'n_counts', 'n_genes', 'annotation_JC', 'sangerID', 'Publication', 'combinedID', 'donor', 'donor_type', 'region', 'region_finest', 'age', 'gender', 'facility', 'cell_or_nuclei', 'modality', 'kit_10x', 'flushed', 'region_cell2loc'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'SYMBOL'\n",
       "    uns: 'spatial'\n",
       "    obsm: 'MT', 'means_cell_abundance_w_sf', 'q05_cell_abundance_w_sf', 'q95_cell_abundance_w_sf', 'spatial', 'stds_cell_abundance_w_sf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-period",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celcomen_tutorial_env",
   "language": "python",
   "name": "celcomen_tutorial_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
